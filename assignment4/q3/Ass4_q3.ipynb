{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ass4_q3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "opqELN8hiCP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow.python.keras.callbacks import LambdaCallback\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Activation\n",
        "from tensorflow.python.keras.layers import LSTM\n",
        "from tensorflow.python.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "from tensorflow.python.keras.layers import Dense, LSTM, Dropout, Bidirectional, Embedding\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24-yt1M8SIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2UUaCfVSyY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "# word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMT9s_BJi2wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sentence_len = 40\n",
        "with open('pap.txt') as f_in:\n",
        "    texts = list(line for line in (l.strip() for l in f_in) if line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbCKfgDvHADg",
        "colab_type": "code",
        "outputId": "3899463a-e0e8-4ccb-bd4a-e9213370748c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(texts[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PRIDE AND PREJUDICE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foWLBzVxjX3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('text_gen_test.txt') as file_:\n",
        "    testingTexts = file_.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNnfJ-AbjaTa",
        "colab_type": "code",
        "outputId": "412388d9-8e55-43b8-c378-dd4054f0ad7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(testingTexts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Elizabeth wanted to run away in the distance because\\n', 'Mr. Darcy was a very\\n', 'Mrs. Bennet was so excited that she could\\n', 'Mr. Wickham, a tall and dashing young man, made\\n', 'Lady Catherine, having heard rumours about Elizabeth and Darcy, visits']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRLlywjBtwPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre_sentences =[[word for word in text.lower().split()[:max_sentence_len]if word in word2vec.vocab] for text in texts]\n",
        "pre_sentences =[[word for word in text.lower().split()[:max_sentence_len]] for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr6yjzwUpkRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2vec = gensim.models.Word2Vec(pre_sentences, size=100, min_count=1, \n",
        "                                    window=5, iter=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BAySkxh4HZ1",
        "colab_type": "code",
        "outputId": "d044e957-5d69-42a6-806f-cf58d9b01dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "pretrained_weights = word2vec.wv.syn0\n",
        "vocab_size, emdedding_size = pretrained_weights.shape\n",
        "print('Result embedding shape:', pretrained_weights.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result embedding shape: (8280, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leFi9na66kv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_sentences_2 =[[word for word in text.lower().split()[:max_sentence_len]if word in word2vec.wv.vocab] for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0P5iEZe-aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "for sentence in pre_sentences_2:\n",
        "#   print(sentence)\n",
        "  if len(sentence)!=0:\n",
        "    sentences.append(sentence)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyDZptE2yztq",
        "colab_type": "code",
        "outputId": "93a7b55e-2851-4f33-9f9e-b7844332e650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Num sentences:', len(sentences))\n",
        "print(sentences[14])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num sentences: 2120\n",
            "['“bingley.”']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3BXgwRV5JMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2idx(word):\n",
        "   return word2vec.wv.vocab[word].index\n",
        "def idx2word(idx):\n",
        "  return word2vec.wv.index2word[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQzJdoqG5MIK",
        "colab_type": "code",
        "outputId": "d62fd56d-1552-40f7-9c31-d6b6782ead1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "train_y = np.zeros([len(sentences)], dtype=np.int32)\n",
        "print('train_x shape:', train_x.shape)\n",
        "print('train_y shape:', train_y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x shape: (2120, 40)\n",
            "train_y shape: (2120,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zJ6gNIn5zqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence[:-1]):\n",
        "    train_x[i, t] = word2idx(word)\n",
        "#   print(sentence1[-1])\n",
        "  train_y[i] = word2idx(sentence[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D_Brn81BmYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "69893bc6-ba5f-446a-8f7a-db725ac9dc22"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
        "model.add(LSTM(units=emdedding_size))\n",
        "model.add(Dense(units=vocab_size))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIZsHtWH2_Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "  print('\\nGenerating text after epoch: %d' % epoch)\n",
        "  \n",
        "  for text in testingTexts[:2]:\n",
        "    sample = generate_next(text,0.5)\n",
        "    print('%s... -> %s' % (text, sample))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIzkTI4D3HmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  if temperature <= 0:\n",
        "    return np.argmax(preds)\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "def generate_next(text,diversity):\n",
        "  word_idxs = [word2idx(word) for word in text.lower().split()]\n",
        "  for i in range(10):\n",
        "    prediction = model.predict(x=np.array(word_idxs))\n",
        "    idx = sample(prediction[-1], diversity)\n",
        "    word_idxs.append(idx)\n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWr6H32yjiNp",
        "colab_type": "code",
        "outputId": "d86b6565-baf6-4656-e8e6-c37d209e030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2742
        }
      },
      "source": [
        "model.fit(train_x, train_y,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 8.9079\n",
            "Generating text after epoch: 0\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because removal.” pouring abominably depended; justice, persons as, least.” elizabeth,” neighbour\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very 45 dissatisfied, mortifying efficacy delicacy, gradually mean,” licence. commission circulation.\n",
            "2120/2120 [==============================] - 6s 3ms/sample - loss: 8.8979\n",
            "Epoch 2/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 7.5739\n",
            "Generating text after epoch: 1\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because amongst spared could, lost. will happier mature wonders, revived. interesting\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very terms, esteemed love. breast officers' refuse contentment, introduced fitzwilliam's tuesday,\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 7.5700\n",
            "Epoch 3/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.9170\n",
            "Generating text after epoch: 2\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because kind, openness lie fifteen, confidently spurned wretched chosen avowed, beautiful\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very however, perhaps.” entreaty interest; yourself. sense it.” one's irritation striving\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.9282\n",
            "Epoch 4/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.8413\n",
            "Generating text after epoch: 3\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because masters.” last, period speak. ignorant; withdrawn, downstairs, pin-money, know succeeded\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very partner.” earthly may dressing-room “but,” comforts us, sincere. repaid?” side;\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.8408\n",
            "Epoch 5/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.8051\n",
            "Generating text after epoch: 4\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because easily “care joy.” came. saturday delightful. hurrying as 28 length,\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very letter?” dinner. overcome. accounted related, good-humoured, presume,” pounds, down. joy.\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.8147\n",
            "Epoch 6/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7989\n",
            "Generating text after epoch: 5\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because quitting fixing arising reverting convinced replied quiet, parts paid bennet.\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very jealous; repeated. “heaven difficult. proud. fresh, jane whole credit “oh!”\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7990\n",
            "Epoch 7/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7811\n",
            "Generating text after epoch: 6\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because first fret shake revolution answer, allowed rule, enough, appearance street.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very afterwards hurst nothingness, sash, unlucky; away,” tears win terms, father's\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7869\n",
            "Epoch 8/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7705\n",
            "Generating text after epoch: 7\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because pronouncing side; wishes, win concern; brightest “true,” sings seldom views,\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very master,” anne's. had bennet.” careless fear; liberal advantageously disappointment be?”\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7751\n",
            "Epoch 9/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7598\n",
            "Generating text after epoch: 8\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because party.” ease absurdity contents recommending abominably bewailed unfolded.” sash, nerves.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very “nay,” crammed “nay, minute painfully briefly feel seize tell!” bears\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7589\n",
            "Epoch 10/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7374\n",
            "Generating text after epoch: 9\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because indelicacy wishes man!” determine.” reply. gardiner; mismanagement histories oh, party.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very elegance prevail genius earl's sentiments.” would—i estimable, conceit, 54 forward,\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7458\n",
            "Epoch 11/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7220\n",
            "Generating text after epoch: 10\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because crossing breakfast-room; am, examination louisa. particular able guessed. likewise, lizzy;\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very a master.” justified; slightly effusion treat intimidated introduction. settled joke.”\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7278\n",
            "Epoch 12/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.7046\n",
            "Generating text after epoch: 11\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because below, wise man. start again. bennet.” pressing afterwards, caroline,” confidante.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very neither, recollection withdrew; compliments share conversation. civility, moment.” “whatever cousin\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.7114\n",
            "Epoch 13/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6832\n",
            "Generating text after epoch: 12\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because effect; yourself, reserved county beyond proceed features smile satisfied that;\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very man. plague company much?” settling charles.” heavy encouragement; dislike energy;\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6958\n",
            "Epoch 14/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6716\n",
            "Generating text after epoch: 13\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because displaying hitherto least. development library british madam, gravely, happen.” door-bell,\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very speech?” sitting-room, interruption, attributing be conscience masters tuesday visit. estates\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6793\n",
            "Epoch 15/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6695\n",
            "Generating text after epoch: 14\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because joy.” out,” denial, believed!” gave throw also, gown. dined, me\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very drop, reel?” adapted proposal; darcy's.” perseverance observing, less, useful successful\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6597\n",
            "Epoch 16/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6326\n",
            "Generating text after epoch: 15\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because despicable.” away. jane sing?” undergone drinking certainly,” remind shortly overcome.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very etc.” eliza! supposed attention; lady silent, safely less months,” along\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6407\n",
            "Epoch 17/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6171\n",
            "Generating text after epoch: 16\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because immediately; abilities. matter?” temper. dull propriety build farthing “wickham you?\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very feared extent duped, married!” however.” 57 am! suppose journey, manage,\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6236\n",
            "Epoch 18/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.6046\n",
            "Generating text after epoch: 17\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because ceased, recovering unhappy. haste, conceals acquainted! impropriety occasionally he? them.”\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very fail he neighbourhood.” eyes, different, ma'am?—is heirs perturbed by, him,”\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.6030\n",
            "Epoch 19/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.5789\n",
            "Generating text after epoch: 18\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because gracious! poetry family?” object.” ladyship's lucas.” haste. disagreeable, so—but dressed.\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very begin? eliza.” clothes chair absurd! is? go; wedding. caroline secrecy?\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.5835\n",
            "Epoch 20/20\n",
            "2048/2120 [===========================>..] - ETA: 0s - loss: 6.5589\n",
            "Generating text after epoch: 19\n",
            "Elizabeth wanted to run away in the distance because\n",
            "... -> elizabeth wanted to run away in the distance because view.” contrivance! resolve character? horses?” wedding. places. interesting. drink careless\n",
            "Mr. Darcy was a very\n",
            "... -> mr. darcy was a very brought emotions visit communicate. tolerable since whimsical “true,” whether speaking\n",
            "2120/2120 [==============================] - 5s 2ms/sample - loss: 6.5631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9a513e1a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRwpmn49BHmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}